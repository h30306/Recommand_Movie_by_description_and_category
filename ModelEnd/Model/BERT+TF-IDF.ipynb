{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T06:37:47.167348Z",
     "start_time": "2020-12-03T06:37:47.130646Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "from bert_serving.client import BertClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T07:20:56.876351Z",
     "start_time": "2020-12-06T07:20:56.533224Z"
    }
   },
   "outputs": [],
   "source": [
    "IMDB = pd.read_csv('data/IMDB_movie_V1_clear.csv')\n",
    "IMDB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T05:57:49.872916Z",
     "start_time": "2020-12-03T05:57:49.842686Z"
    }
   },
   "outputs": [],
   "source": [
    "segments = [' '.join(eval(x)+eval(y)) for x,y in IMDB[['keywords','Genres']].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T09:02:35.541274Z",
     "start_time": "2020-12-06T09:02:35.045053Z"
    }
   },
   "outputs": [],
   "source": [
    "# create bag-of-word model and fit the documents\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "print('vectorizer', vectorizer)\n",
    "\n",
    "vectorizer.fit(segments)\n",
    "print('Number of vocabulary', len(vectorizer.vocabulary_))\n",
    "print('Vocabulary', vectorizer.vocabulary_)\n",
    "print('feature name', vectorizer.get_feature_names())\n",
    "\n",
    "# TF\n",
    "vectorizer = CountVectorizer(binary=False)\n",
    "print('vectorizer', vectorizer)\n",
    "\n",
    "vectorizer.fit(segments)\n",
    "print('Number of vocabulary', len(vectorizer.vocabulary_))\n",
    "print('Vocabulary', vectorizer.vocabulary_)\n",
    "print('feature name', vectorizer.get_feature_names())\n",
    "\n",
    "# Term Frequency inverse Document Frequency\n",
    "vectorizer = TfidfVectorizer(use_idf=True, norm=None, smooth_idf=False)\n",
    "vectorizer.fit(segments)\n",
    "X = vectorizer.transform(segments).toarray()\n",
    "print(vectorizer.get_feature_names())\n",
    "print(vectorizer.idf_)\n",
    "print('word by doc.:')\n",
    "print(X.transpose())\n",
    "\n",
    "#cosine similarity\n",
    "print('by documents')\n",
    "print(cosine_similarity(X, X))\n",
    "print('by words')\n",
    "print(cosine_similarity(X.transpose(), X.transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T06:22:06.595218Z",
     "start_time": "2020-12-03T06:22:06.556089Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open(\"vectorizer.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-06T09:03:09.934116Z",
     "start_time": "2020-12-06T09:03:09.881541Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('TFIDF.npy', 'wb') as f:\n",
    "    np.save(f, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T06:42:25.745368Z",
     "start_time": "2020-12-03T06:41:46.923120Z"
    }
   },
   "outputs": [],
   "source": [
    "#取得詞向量\n",
    "bc = BertClient() # 取得bert服務器資源\n",
    "print('BERT')\n",
    "sents_enc = bc.encode(IMDB['StoryLine'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T06:57:50.245589Z",
     "start_time": "2020-12-03T06:57:50.206722Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('BERT.npy', 'wb') as f:\n",
    "    np.save(f, sents_enc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
